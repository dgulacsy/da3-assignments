---
title: "Finding fast growing firms"
subtitle: "DA3 Assignment 2"
author: "Attila Szuts, Dominik Gulacsy"
date: "2/10/2021"
code_download: yes
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

## [Github Repo](https://github.com/dgulacsy/da3-assignments/tree/main/da3-assignment2)

```{r}
rm(list = ls())
library(tidyverse)
library(caret)
library(party)
library(GGally)
library(pROC)

source("codes/helper.R")
```

# Introduction



# Data Cleaning/Wrangling





# Model preparation

## Train test split

```{r}
df <- read_rds("data/clean/fast-growth-firms-workfile.rds")

# skim(df)

# create smaller sample to test models
# samp_size <- round(nrow(df) / 20)
# set.seed(1234)
# df <- sample_n(df, samp_size)


set.seed(1234)
training_ratio <- 0.7
train_indices <- createDataPartition(
  y = df[["is_fg"]],
  times = 1,
  p = training_ratio,
  list = FALSE
) %>% as.vector()
data_train <- df[train_indices, ]
data_test <- df[-train_indices, ]
```

## Variable selection

```{r}
target <- c("is_fg")
business <- c("ind2_cat","urban","region","labor_avg","age","age2","new")
ceo <- c("ceo_inoffice_years","ceo_age","ceo_count",
        "ceo_female","ceo_foreign","ceo_gender","ceo_origin")
sales <- c("sales_mil_log","d1_sales_mil_log")
financial_basic <- c("curr_assets","curr_liab","fixed_assets","tang_assets",
                     "intang_assets","inventories","liq_assets","subscribed_cap",
                     "share_eq","material_exp","personnel_exp","amort","profit","d1_profit")
financial_ext <- c("extra_exp","extra_inc","extra_profit_loss","inc_bef_tax")
financial_basic_ratios <- colnames(df %>% select(matches("*._bs|*._pl")))
financial_ext_ratios <- colnames(df %>% select(matches("*._ratio")))
flags <- colnames(df %>% select(matches("*.flag.")))

formula_lpm = formula(paste0(target, paste0(" ~ ",paste(c(business, ceo,sales, financial_basic, financial_ext, financial_basic_ratios, flags),collapse = " + "))))
formula_log = formula(paste0(target, paste0(" ~ ",paste(c(business, ceo,sales, financial_basic, financial_ext, financial_basic_ratios, flags),collapse = " + ")))) 
formula_rf = formula(paste0(target, paste0(" ~ ",paste(c(business, financial_basic, flags),collapse = " + "))))  # ceo,sales, financial_ext, financial_basic_ratios, 
formula_gbm = formula(paste0(target, paste0(" ~ ",paste(c(business, financial_basic, flags),collapse = " + "))))  # ceo,sales, financial_ext, financial_basic_ratios, 
formula_knn = formula(paste0(target, paste0(" ~ ",paste(c(business, financial_basic, flags),collapse = " + "))))  # ceo,sales, financial_ext, financial_basic_ratios, 
formula_enet = formula(paste0(target, paste0(" ~ ",paste(c(business, financial_basic, flags),collapse = " + "))))  # ceo,sales, financial_ext, financial_basic_ratios, 
```

# EDA
```{r}
df %>% select(where(is.numeric)) %>% ggcorr(layout.exp = 1)
ggpairs(df, columns = c(target, business))

# Check for multicollinearity and perfect collinearity
numeric_df <- keep( df , is.numeric )
cT <- cor(numeric_df , use = "complete.obs")

# Check for highly correlated values:
sum( abs( cT ) >= 0.8 & cT != 1 ) / 2
# Find the correlations which are higher than 0.8
id_cr <- which( abs( cT ) >= 0.8 & cT != 1 )
pair_names <- expand.grid( variable.names(numeric_df) , variable.names(numeric_df) )
# Get the pairs:
high_corr <- pair_names[ id_cr , ]
high_corr <- mutate( high_corr , corr_val = cT[ id_cr ] )
high_corr <- mutate(high_corr, Var1 = as.character(Var1))
high_corr <- mutate(high_corr, Var2 = as.character(Var2))
high_corr$vars<-unlist(lapply(1:nrow(high_corr),function(i){
  paste(sort(c(high_corr$Var1[i],high_corr$Var2[i])), collapse = "")
}))
high_corr<-high_corr[!duplicated(high_corr$vars),]
high_corr
```

# Modelling

```{r}
results <- list()
```


## LPM

```{r}
set.seed(1234)
train_control <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = TRUE
)

start <- Sys.time()
model_lpm <- train(
    formula_log,
    method = "glm",
    data = data_train,
    trControl = train_control,
    na.action = na.omit,
    metric = "ROC"
  )
end <- Sys.time()

modelname <- "lpm model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))



results[["roc_lpm"]] <- mean(model_lpm$resample$ROC)
```


## Logit

```{r}
set.seed(1234)
train_control <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = TRUE
)

start <- Sys.time()
model_logit <- train(
    formula_log,
    method = "glm",
    data = data_train,
    family = binomial,
    trControl = train_control,
    na.action = na.omit,
    metric = "ROC"
  )
end <- Sys.time()
# 
# Warning messages:
# 1: glm.fit: algorithm did not converge 
# 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
# 
results[["roc_logit"]] <- mean(model_logit$results$ROC)
modelname <- "logit model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))
```


## Probit

```{r}
set.seed(1234)
train_control <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = TRUE
)

start <- Sys.time()
model_probit <- train(
    formula_log,
    method = "glm",
    data = data_train,
    family = binomial(link = "probit"),
    trControl = train_control,
    na.action = na.omit,
    metric = "ROC"
  )
end <- Sys.time()
results[["roc_probit"]] <- mean(model_probit$results$ROC)

modelname <- "probit model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))
```

## Random Forest

```{r}
set.seed(1234)
trctrl <- trainControl(method = "cv", 
                       number = 10, 
                       classProbs = TRUE, 
                       summaryFunction = twoClassSummary,
                       savePredictions = TRUE,
                       verboseIter = TRUE)
tune_grid <- expand.grid(
  .mtry = c(5, 6, 7),
  .splitrule = "gini",
  .min.node.size = c(10, 15)
)

start <- Sys.time()
# use all variables?
model_rf <- train(formula_rf,
                  data = data_train, 
                  method = "rf",
                  metric = "ROC",
                  trControl=trctrl,
                  # tuneGrid =tune_grid,
                  num.threads = 7,
                  na.action = na.omit)
end <- Sys.time()

results[["roc_random_forest"]] <- mean(model_rf$results$ROC)

postResample(data_test$is_fg, predict(model_rf, data_test))

# colnames(data_test, 2)
time <- as.numeric(round(end - start, 2), unit = "mins")

modelname <- "random forest model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))
```

## Boosting

```{r}
set.seed(1234)
start_time <- Sys.time()
# Train model with preprocessing & repeated cv
trctrl <- trainControl(method = "repeatedcv", 
                       number = 10, 
                       repeats = 1, 
                       verboseIter = TRUE, classProbs = TRUE, summaryFunction = twoClassSummary)

model_gbm <- train(formula_gbm,
                   data = data_train,
                   method = "gbm",
                   trControl = trctrl,
                   verbose = 0,
                   # num.threads = 7,
                   na.action = na.omit)
end_time <- Sys.time()

results[["roc_gbm"]] <- mean(model_gbm$results$ROC)

print(end_time - start_time)

modelname <- "gbm model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))
```


## KNN

```{r}
set.seed(1234)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1, verboseIter = TRUE, classProbs = TRUE, summaryFunction = twoClassSummary)

start <- Sys.time()
model_knn <- train(formula_knn, data = data_train, method = "knn",
                 trControl=trctrl,
                 preProcess=c("center", "scale"),
                 tuneLength=20,
                 # num.threads = 7
                 na.action = na.omit
                 #tuneGrid = data.frame(k=c(2:8))
                 )
end <- Sys.time()

results[["roc_knn"]] <- mean(model_knn$results$ROC)

modelname <- "knn model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))

knnModelRoc <- roc(predictor = predict(model_knn, data_test, type='prob', decision.values=T)$f_is_fg, response = data_test$f_is_fg)

# 
# Error in roc.default(predictor = predict(model_knn, data_test, type = "prob",  : 
#  No valid data provided.
#

knnModelRoc
plot(knnModelRoc)

postResample(SpamTest$count, predict(model_knn, SpamTest))
```


## Elastic Net
```{r}
enet_tune_grid <- expand.grid(
  "alpha" = seq(0, 1, by = 0.1),
  "lambda" = seq(0.05, 0.5, by = 0.025)
)

fit_control <- trainControl(method = "cv", 
                            number = 10,
                            verboseIter = TRUE, classProbs = TRUE, summaryFunction = twoClassSummary)
                            

set.seed(1234)
start <- Sys.time()
enet_fit <- train(
  formula_enet,
  data = data_train,
  method = "glmnet",
  preProcess = c("center", "scale"),
  tuneGrid = enet_tune_grid,
  family = "binomial",
  trControl = fit_control,
  na.action = na.omit
)
end <- Sys.time()

results[["roc_elastic_net"]] <- mean(enet_fit$results$ROC)

lmElasticNetCaretRoc <- roc(predictor = predict(enet_fit, data_test, type='prob', decision.values=T), response = data_test$f_is_fg)

# 
# Error in colnames(data) : argument "data" is missing, with no default
# 

lmElasticNetCaretRoc
plot(lmElasticNetCaretRoc)

confusionMatrix(data_test$is_fg, predict(enet_fit, data_test, decision.values=T))

plot(enet_fit)

coef(enet_fit$finalModel, enet_fit$bestTune$lambda)
postResample(data_test$is_fg, predict(lmElasticNetCaret, data_test))


modelname <- "elastic net model"
time <- as.numeric(round(end - start, 2), unit = "mins")
send_message(my_text = paste0(user, " your ", modelname, " has finished training! It took: ", time, " minutes"))
```

